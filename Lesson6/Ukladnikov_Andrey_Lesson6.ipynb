{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 6. Рекуррентные нейронные сети. LSTM. GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 1.\n",
    "\n",
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>tweet_vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "      <td>[[0.40891476115211844, 0.18360024644061923, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[[0.4508066247491276, 0.17692823379355319, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[[0.7542365392049154, 0.5224650899569193, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love take with all the time in ur</td>\n",
       "      <td>[model, love, take, with, all, the, time, in, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[[0.49165773598684204, 0.2370210364460945, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[[0.3752712719142437, 0.1220138180651702, -0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id  label                                              tweet  \\\n",
       "0      0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1      1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2      2   3    0.0                                bihday your majesty   \n",
       "3      3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4      4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3            model love take with all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, take, with, all, the, time, in, ur]   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \\\n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                          tweet_vecs  \n",
       "0  [[0.40891476115211844, 0.18360024644061923, -0...  \n",
       "1  [[0.4508066247491276, 0.17692823379355319, -0....  \n",
       "2  [[0.7542365392049154, 0.5224650899569193, 0.00...  \n",
       "3  [[0.49165773598684204, 0.2370210364460945, -0....  \n",
       "4  [[0.3752712719142437, 0.1220138180651702, -0.1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('combine_df.pickle', 'rb') as f:\n",
    "    combine_df = pickle.load(f)\n",
    "    \n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['label'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04560711161740475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_df[combine_df['label']>0])/len(combine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x, df_val_x, df_train_y, df_val_y = train_test_split(combine_df['clean_tweet'], combine_df['label'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045439519922699415"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_y[df_train_y>0])/len(df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04627746135069162"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val_y[df_val_y>0])/len(df_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19249    well donald trump has officially reached the b...\n",
       "30071           this looks like molly old boyfriend gunner\n",
       "7869     weeks on this picture weeks on monday not long...\n",
       "4087     these niggas burning will not let you know the...\n",
       "2282                                             well done\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_x=pd.DataFrame(data=df_train_x.values,index=df_train_x.index,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19249</th>\n",
       "      <td>well donald trump has officially reached the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30071</th>\n",
       "      <td>this looks like molly old boyfriend gunner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>weeks on this picture weeks on monday not long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>these niggas burning will not let you know the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>well done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "19249  well donald trump has officially reached the b...\n",
       "30071         this looks like molly old boyfriend gunner\n",
       "7869   weeks on this picture weeks on monday not long...\n",
       "4087   these niggas burning will not let you know the...\n",
       "2282                                           well done"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4925     fitcamp tonight at manupmonday letssss go heal...\n",
       "19869           always love good friday selfie vain friday\n",
       "34470    she seems to have split personality rav does t...\n",
       "48729    isis is so weak call identify any man in front...\n",
       "15460    operation jefferson jay covers bob ross remixe...\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val_x=pd.DataFrame(data=df_val_x.values,index=df_val_x.index,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>fitcamp tonight at manupmonday letssss go heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19869</th>\n",
       "      <td>always love good friday selfie vain friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34470</th>\n",
       "      <td>she seems to have split personality rav does t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48729</th>\n",
       "      <td>isis is so weak call identify any man in front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15460</th>\n",
       "      <td>operation jefferson jay covers bob ross remixe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "4925   fitcamp tonight at manupmonday letssss go heal...\n",
       "19869         always love good friday selfie vain friday\n",
       "34470  she seems to have split personality rav does t...\n",
       "48729  isis is so weak call identify any man in front...\n",
       "15460  operation jefferson jay covers bob ross remixe..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "ds_train_x['text'] = ds_train_x['text'].apply(preprocess_text)\n",
    "ds_val_x['text'] = ds_val_x['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = ds_train_x['text'].values\n",
    "text_corpus_valid = ds_val_x['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train_y.values\n",
    "y_val = df_val_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0172 - accuracy: 0.9928 - val_loss: 0.1786 - val_accuracy: 0.9547\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0147 - accuracy: 0.9930 - val_loss: 0.1960 - val_accuracy: 0.9570\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0133 - accuracy: 0.9934 - val_loss: 0.2133 - val_accuracy: 0.9601\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 0.0141 - accuracy: 0.9926 - val_loss: 0.2006 - val_accuracy: 0.9532\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0124 - accuracy: 0.9936 - val_loss: 0.2174 - val_accuracy: 0.9532\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 2s 30ms/step - loss: 0.0116 - accuracy: 0.9938 - val_loss: 0.2187 - val_accuracy: 0.9527\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0109 - accuracy: 0.9938 - val_loss: 0.2401 - val_accuracy: 0.9565\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0108 - accuracy: 0.9934 - val_loss: 0.2424 - val_accuracy: 0.9558\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0107 - accuracy: 0.9937 - val_loss: 0.2387 - val_accuracy: 0.9591\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0105 - accuracy: 0.9940 - val_loss: 0.2457 - val_accuracy: 0.9558\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0105 - accuracy: 0.9932 - val_loss: 0.2423 - val_accuracy: 0.9512\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0103 - accuracy: 0.9940 - val_loss: 0.2494 - val_accuracy: 0.9502\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0099 - accuracy: 0.9936 - val_loss: 0.2743 - val_accuracy: 0.9555\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 5s 71ms/step - loss: 0.0104 - accuracy: 0.9940 - val_loss: 0.2634 - val_accuracy: 0.9519\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 3s 45ms/step - loss: 0.0098 - accuracy: 0.9942 - val_loss: 0.2712 - val_accuracy: 0.9542\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 2s 31ms/step - loss: 0.0099 - accuracy: 0.9942 - val_loss: 0.3152 - val_accuracy: 0.9588\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0104 - accuracy: 0.9940 - val_loss: 0.2723 - val_accuracy: 0.9575\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0100 - accuracy: 0.9937 - val_loss: 0.2811 - val_accuracy: 0.9537\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0100 - accuracy: 0.9939 - val_loss: 0.2818 - val_accuracy: 0.9517\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0098 - accuracy: 0.9943 - val_loss: 0.2935 - val_accuracy: 0.9540\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 3s 41ms/step - loss: 0.0097 - accuracy: 0.9941 - val_loss: 0.2836 - val_accuracy: 0.9509\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0097 - accuracy: 0.9940 - val_loss: 0.3053 - val_accuracy: 0.9499\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0097 - accuracy: 0.9943 - val_loss: 0.2950 - val_accuracy: 0.9532\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 0.3016 - val_accuracy: 0.9540\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 3s 46ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 0.2975 - val_accuracy: 0.9509\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 3s 38ms/step - loss: 0.0095 - accuracy: 0.9943 - val_loss: 0.3224 - val_accuracy: 0.9547\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0094 - accuracy: 0.9939 - val_loss: 0.3274 - val_accuracy: 0.9522\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0095 - accuracy: 0.9943 - val_loss: 0.3210 - val_accuracy: 0.9550\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0096 - accuracy: 0.9939 - val_loss: 0.3223 - val_accuracy: 0.9514\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0097 - accuracy: 0.9942 - val_loss: 0.3063 - val_accuracy: 0.9565\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 2s 33ms/step - loss: 0.0096 - accuracy: 0.9943 - val_loss: 0.2963 - val_accuracy: 0.9481\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0094 - accuracy: 0.9943 - val_loss: 0.3213 - val_accuracy: 0.9525\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 4s 50ms/step - loss: 0.0096 - accuracy: 0.9943 - val_loss: 0.3293 - val_accuracy: 0.9545\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0095 - accuracy: 0.9941 - val_loss: 0.3239 - val_accuracy: 0.9537\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 3s 36ms/step - loss: 0.0095 - accuracy: 0.9941 - val_loss: 0.3371 - val_accuracy: 0.9517\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0095 - accuracy: 0.9941 - val_loss: 0.3493 - val_accuracy: 0.9565\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0093 - accuracy: 0.9943 - val_loss: 0.3519 - val_accuracy: 0.9522\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0094 - accuracy: 0.9944 - val_loss: 0.3387 - val_accuracy: 0.9519\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0098 - accuracy: 0.9939 - val_loss: 0.3166 - val_accuracy: 0.9525\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0099 - accuracy: 0.9941 - val_loss: 0.3501 - val_accuracy: 0.9357\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 3s 46ms/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 0.3046 - val_accuracy: 0.9527\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 0.0097 - accuracy: 0.9943 - val_loss: 0.3201 - val_accuracy: 0.9519\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0100 - accuracy: 0.9940 - val_loss: 0.3490 - val_accuracy: 0.9517\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0094 - accuracy: 0.9943 - val_loss: 0.4001 - val_accuracy: 0.9481\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0099 - accuracy: 0.9942 - val_loss: 0.3523 - val_accuracy: 0.9474\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 2s 32ms/step - loss: 0.0095 - accuracy: 0.9939 - val_loss: 0.3467 - val_accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 0.0095 - accuracy: 0.9944 - val_loss: 0.3677 - val_accuracy: 0.9512\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 3s 43ms/step - loss: 0.0100 - accuracy: 0.9940 - val_loss: 0.3498 - val_accuracy: 0.9512\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 2s 34ms/step - loss: 0.0099 - accuracy: 0.9941 - val_loss: 0.3563 - val_accuracy: 0.9522\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 2s 35ms/step - loss: 0.0096 - accuracy: 0.9943 - val_loss: 0.3434 - val_accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "#early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)#,\n",
    "                    #callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 14ms/step - loss: 0.3810 - accuracy: 0.9410\n",
      "\n",
      "\n",
      "Test score: 0.38096410036087036\n",
      "Test accuracy: 0.9410089254379272\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 8s 72ms/step - loss: 0.4191 - accuracy: 0.9271 - val_loss: 0.1681 - val_accuracy: 0.9593\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.1842 - accuracy: 0.9549 - val_loss: 0.1205 - val_accuracy: 0.9606\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0960 - accuracy: 0.9640 - val_loss: 0.1157 - val_accuracy: 0.9560\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0616 - accuracy: 0.9745 - val_loss: 0.1345 - val_accuracy: 0.9575\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0452 - accuracy: 0.9831 - val_loss: 0.1672 - val_accuracy: 0.9593\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.1781 - val_accuracy: 0.9588\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 0.1913 - val_accuracy: 0.9466\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 5s 70ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.2078 - val_accuracy: 0.9522\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 5s 65ms/step - loss: 0.0245 - accuracy: 0.9904 - val_loss: 0.2733 - val_accuracy: 0.9588\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 0.2438 - val_accuracy: 0.9535\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.2370 - val_accuracy: 0.9502\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0190 - accuracy: 0.9925 - val_loss: 0.2718 - val_accuracy: 0.9532\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0165 - accuracy: 0.9926 - val_loss: 0.2745 - val_accuracy: 0.9522\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.0156 - accuracy: 0.9929 - val_loss: 0.2889 - val_accuracy: 0.9527\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.0174 - accuracy: 0.9917 - val_loss: 0.3016 - val_accuracy: 0.9491\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 0.3183 - val_accuracy: 0.9530\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0142 - accuracy: 0.9927 - val_loss: 0.3429 - val_accuracy: 0.9491\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 4s 64ms/step - loss: 0.0132 - accuracy: 0.9934 - val_loss: 0.3702 - val_accuracy: 0.9527\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 5s 65ms/step - loss: 0.0124 - accuracy: 0.9934 - val_loss: 0.3836 - val_accuracy: 0.9497\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0137 - accuracy: 0.9929 - val_loss: 0.3984 - val_accuracy: 0.9489\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0128 - accuracy: 0.9931 - val_loss: 0.3757 - val_accuracy: 0.9474\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 5s 74ms/step - loss: 0.0133 - accuracy: 0.9934 - val_loss: 0.3951 - val_accuracy: 0.9502\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 5s 75ms/step - loss: 0.0126 - accuracy: 0.9925 - val_loss: 0.4021 - val_accuracy: 0.9491\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 5s 67ms/step - loss: 0.0121 - accuracy: 0.9933 - val_loss: 0.4265 - val_accuracy: 0.9494\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 5s 69ms/step - loss: 0.0115 - accuracy: 0.9937 - val_loss: 0.4773 - val_accuracy: 0.9514\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 4s 59ms/step - loss: 0.0112 - accuracy: 0.9941 - val_loss: 0.5060 - val_accuracy: 0.9497\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0112 - accuracy: 0.9935 - val_loss: 0.4974 - val_accuracy: 0.9476\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0110 - accuracy: 0.9928 - val_loss: 0.4079 - val_accuracy: 0.9453\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0110 - accuracy: 0.9941 - val_loss: 0.4924 - val_accuracy: 0.9519\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0105 - accuracy: 0.9942 - val_loss: 0.4820 - val_accuracy: 0.9458\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0110 - accuracy: 0.9940 - val_loss: 0.5392 - val_accuracy: 0.9509\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0105 - accuracy: 0.9938 - val_loss: 0.5667 - val_accuracy: 0.9507\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0104 - accuracy: 0.9937 - val_loss: 0.5663 - val_accuracy: 0.9484\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0106 - accuracy: 0.9931 - val_loss: 0.6153 - val_accuracy: 0.9497\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0105 - accuracy: 0.9943 - val_loss: 0.4958 - val_accuracy: 0.9486\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0120 - accuracy: 0.9927 - val_loss: 0.6584 - val_accuracy: 0.9514\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0110 - accuracy: 0.9929 - val_loss: 0.5650 - val_accuracy: 0.9413\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0116 - accuracy: 0.9932 - val_loss: 0.5766 - val_accuracy: 0.9385\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0125 - accuracy: 0.9929 - val_loss: 0.5401 - val_accuracy: 0.9494\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 6s 80ms/step - loss: 0.0122 - accuracy: 0.9927 - val_loss: 0.5015 - val_accuracy: 0.9509\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.0108 - accuracy: 0.9930 - val_loss: 0.5143 - val_accuracy: 0.9504\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 5s 69ms/step - loss: 0.0098 - accuracy: 0.9943 - val_loss: 0.6075 - val_accuracy: 0.9456\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 5s 77ms/step - loss: 0.0096 - accuracy: 0.9941 - val_loss: 0.6248 - val_accuracy: 0.9502\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 5s 64ms/step - loss: 0.0112 - accuracy: 0.9933 - val_loss: 0.5455 - val_accuracy: 0.9489\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 6s 89ms/step - loss: 0.0103 - accuracy: 0.9937 - val_loss: 0.5574 - val_accuracy: 0.9494\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 5s 73ms/step - loss: 0.0110 - accuracy: 0.9938 - val_loss: 0.5775 - val_accuracy: 0.9486\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 5s 66ms/step - loss: 0.0110 - accuracy: 0.9927 - val_loss: 0.5983 - val_accuracy: 0.9486\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 6s 80ms/step - loss: 0.0122 - accuracy: 0.9932 - val_loss: 0.5251 - val_accuracy: 0.9464\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 4s 62ms/step - loss: 0.0114 - accuracy: 0.9937 - val_loss: 0.5742 - val_accuracy: 0.9514\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 5s 69ms/step - loss: 0.0103 - accuracy: 0.9936 - val_loss: 0.5700 - val_accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5619 - accuracy: 0.9423\n",
      "\n",
      "\n",
      "Test score: 0.5619032979011536\n",
      "Test accuracy: 0.9423311352729797\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(GRU(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 7s 61ms/step - loss: 0.4690 - accuracy: 0.9251 - val_loss: 0.1495 - val_accuracy: 0.9593\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.1434 - accuracy: 0.9554 - val_loss: 0.1198 - val_accuracy: 0.9570\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0762 - accuracy: 0.9697 - val_loss: 0.1266 - val_accuracy: 0.9527\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0522 - accuracy: 0.9803 - val_loss: 0.1481 - val_accuracy: 0.9547\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.1737 - val_accuracy: 0.9535\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.2183 - val_accuracy: 0.9565\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0268 - accuracy: 0.9885 - val_loss: 0.2250 - val_accuracy: 0.9535\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.2059 - val_accuracy: 0.9547\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.2397 - val_accuracy: 0.9484\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 5s 70ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 0.2482 - val_accuracy: 0.9476\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 0.2552 - val_accuracy: 0.9568\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.2639 - val_accuracy: 0.9436\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0212 - accuracy: 0.9917 - val_loss: 0.2872 - val_accuracy: 0.9517\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0183 - accuracy: 0.9919 - val_loss: 0.2752 - val_accuracy: 0.9491\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0150 - accuracy: 0.9931 - val_loss: 0.2808 - val_accuracy: 0.9456\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.3227 - val_accuracy: 0.9573\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.0155 - accuracy: 0.9933 - val_loss: 0.2982 - val_accuracy: 0.9502\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0146 - accuracy: 0.9931 - val_loss: 0.2841 - val_accuracy: 0.9479\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0139 - accuracy: 0.9931 - val_loss: 0.3137 - val_accuracy: 0.9476\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 6s 81ms/step - loss: 0.0148 - accuracy: 0.9920 - val_loss: 0.3019 - val_accuracy: 0.9453\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0134 - accuracy: 0.9937 - val_loss: 0.2931 - val_accuracy: 0.9461\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0148 - accuracy: 0.9926 - val_loss: 0.3416 - val_accuracy: 0.9547\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0122 - accuracy: 0.9936 - val_loss: 0.3477 - val_accuracy: 0.9519\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0123 - accuracy: 0.9934 - val_loss: 0.3156 - val_accuracy: 0.9415\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0134 - accuracy: 0.9928 - val_loss: 0.3667 - val_accuracy: 0.9458\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 6s 83ms/step - loss: 0.0127 - accuracy: 0.9929 - val_loss: 0.3765 - val_accuracy: 0.9464\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 4s 54ms/step - loss: 0.0115 - accuracy: 0.9933 - val_loss: 0.3614 - val_accuracy: 0.9418\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0121 - accuracy: 0.9929 - val_loss: 0.4195 - val_accuracy: 0.9494\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 5s 78ms/step - loss: 0.0110 - accuracy: 0.9932 - val_loss: 0.4382 - val_accuracy: 0.9494\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 4s 61ms/step - loss: 0.0115 - accuracy: 0.9940 - val_loss: 0.3974 - val_accuracy: 0.9489\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 7s 93ms/step - loss: 0.0120 - accuracy: 0.9926 - val_loss: 0.4019 - val_accuracy: 0.9443\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 5s 73ms/step - loss: 0.0112 - accuracy: 0.9920 - val_loss: 0.4111 - val_accuracy: 0.9425\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0110 - accuracy: 0.9933 - val_loss: 0.4131 - val_accuracy: 0.9461\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0108 - accuracy: 0.9929 - val_loss: 0.4250 - val_accuracy: 0.9397\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 5s 64ms/step - loss: 0.0112 - accuracy: 0.9924 - val_loss: 0.4199 - val_accuracy: 0.9395\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 6s 78ms/step - loss: 0.0110 - accuracy: 0.9925 - val_loss: 0.4590 - val_accuracy: 0.9446\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 0.0102 - accuracy: 0.9935 - val_loss: 0.4508 - val_accuracy: 0.9448\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 0.0108 - accuracy: 0.9928 - val_loss: 0.4203 - val_accuracy: 0.9428\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 6s 83ms/step - loss: 0.0099 - accuracy: 0.9935 - val_loss: 0.4534 - val_accuracy: 0.9418\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 4s 60ms/step - loss: 0.0106 - accuracy: 0.9928 - val_loss: 0.4957 - val_accuracy: 0.9466\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 0.0111 - accuracy: 0.9927 - val_loss: 0.4616 - val_accuracy: 0.9405\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 5s 73ms/step - loss: 0.0104 - accuracy: 0.9925 - val_loss: 0.4794 - val_accuracy: 0.9430\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 5s 76ms/step - loss: 0.0096 - accuracy: 0.9933 - val_loss: 0.5276 - val_accuracy: 0.9448\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0107 - accuracy: 0.9931 - val_loss: 0.5325 - val_accuracy: 0.9466\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 4s 58ms/step - loss: 0.0097 - accuracy: 0.9933 - val_loss: 0.5226 - val_accuracy: 0.9448\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 6s 87ms/step - loss: 0.0102 - accuracy: 0.9932 - val_loss: 0.4989 - val_accuracy: 0.9446\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 4s 57ms/step - loss: 0.0098 - accuracy: 0.9935 - val_loss: 0.5465 - val_accuracy: 0.9448\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 6s 87ms/step - loss: 0.0092 - accuracy: 0.9942 - val_loss: 0.5326 - val_accuracy: 0.9458\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 5s 73ms/step - loss: 0.0098 - accuracy: 0.9934 - val_loss: 0.5268 - val_accuracy: 0.9410\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 4s 63ms/step - loss: 0.0104 - accuracy: 0.9935 - val_loss: 0.4824 - val_accuracy: 0.9385\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.9423\n",
      "\n",
      "\n",
      "Test score: 0.512185275554657\n",
      "Test accuracy: 0.9423311352729797\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод - немного лучше и одинаково работают LSTM и  GRU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 2\n",
    "\n",
    "Провести анализ как лучше генерировать текст по словам или символам ноутбук text_generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n",
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                       \n"
     ]
    }
   ],
   "source": [
    "path_to_file = 'evgenyi_onegin.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))\n",
    "print(text[:250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация текста по символам**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "#text_as_int, text, len(text_as_int), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А\n",
      "л\n",
      "е\n",
      "к\n",
      "с\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
      "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
      "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
      "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
      "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
      "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (64, None, 256)           33536     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (64, None, 131)           134275    \n",
      "=================================================================\n",
      "Total params: 4,106,115\n",
      "Trainable params: 4,106,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 131)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.880374\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 50s 1s/step - loss: 3.8858\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 48s 1s/step - loss: 1.7990\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 49s 1s/step - loss: 1.6012\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 48s 1s/step - loss: 1.4548\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 48s 1s/step - loss: 1.3631\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 48s 1s/step - loss: 1.3171\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 49s 1s/step - loss: 1.2769\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 49s 1s/step - loss: 1.2560\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 50s 1s/step - loss: 1.2226\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 49s 1s/step - loss: 1.2052\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (1, None, 256)            33536     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (1, None, 131)            134275    \n",
      "=================================================================\n",
      "Total params: 4,106,115\n",
      "Trainable params: 4,106,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 500\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж месяц был силь\n",
      "              . . . . . . \" На ягоят свовка.\n",
      "                    Оны, придет снае швой..... - деться, писхов,\n",
      "                         Она пилска. луквезскийшо.\n",
      "                          И удрамную Евгогий\n",
      "                       На мнегда доль отни слов медить,\n",
      "                            Тум педрурсцевуя капить {3}}\n",
      "                     В жу ут писманялаоколком,\n",
      "     Подетатся стаза,\n",
      "                      Блаждука моден овщем\n",
      "                       Кво дутяль оз раро ум.\n",
      "\n",
      "                 \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Уж месяц был \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[104   1 103 ... 113 116 104]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [110 129 103 ...  99 111   1]\n",
      " ...\n",
      " [126 108   1 ...   1 112  99]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   0   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1 103 118 ... 116 104 111]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [129 103 107 ... 111   1 103]\n",
      " ...\n",
      " [108   1 102 ... 112  99 116]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[127   9   9 ... 117 127   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   0   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 106 107 110]\n",
      " [  1   1   1 ...   0   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  9   9   9 ... 127   1 105]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 107 110 116]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [115 104 123 ...   1   1   1]\n",
      " [104   1 114 ... 113   1 117]\n",
      " ...\n",
      " [  3   9   0 ... 113 115 107]\n",
      " [118 111   1 ...   1  85 115]\n",
      " [113   1 100 ... 115 104 114]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [104 123 118 ...   1   1   1]\n",
      " [  1 114 115 ...   1 117  99]\n",
      " ...\n",
      " [  9   0   1 ... 115 107 111]\n",
      " [111   1 107 ...  85 115 107]\n",
      " [  1 100 126 ... 104 114 104]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [127   1 123 ...   1 101 104]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 107   1 ... 100 104 102]\n",
      " [100 113 110 ... 112  99   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 123 118 ... 101 104 122]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [107   1 116 ... 104 102 113]\n",
      " [113 110 107 ...  99   1 114]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 113 107 106]\n",
      " [ 61  45  22 ...   1 115  99]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [109   1  80 ... 104 112 113]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  9   9   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 107 106 101]\n",
      " [ 45  22   9 ... 115  99 103]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1  80  99 ... 112 113 116]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  9   1 109 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 43  31   0 ... 115 107   9]\n",
      " [104   1 116 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [103 118   1 ... 113 101 107]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [104 116 117 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 31   0   0 ... 107   9   0]\n",
      " [  1 116 110 ...   1   1  74]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [118   1 116 ... 101 107 117]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [116 117 126 ...   1   1  83]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[106 112 113 ...  99   9   0]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 116 117 107]\n",
      " ...\n",
      " [104 103 110 ... 127 104   1]\n",
      " [  1 109   1 ...   1   1   1]\n",
      " [  0   1   1 ... 112 126 120]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[112 113 108 ...   9   0   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 117 107 110]\n",
      " ...\n",
      " [103 110 107 ... 104   1 110]\n",
      " [109   1 117 ...   1   1  71]\n",
      " [  1   1   1 ... 126 120   7]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1  84 ...   1   1  79]\n",
      " [  0   1   1 ...   1   1   1]\n",
      " [  9   0   0 ...   1   1   1]\n",
      " ...\n",
      " [124 107 108 ... 104 103   1]\n",
      " [  3   0   1 ... 104   1 106]\n",
      " [127 130   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1  84 112 ...   1  79   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  0   0   1 ...   1   1   1]\n",
      " ...\n",
      " [107 108   7 ... 103   1 123]\n",
      " [  0   1   1 ...   1 106  99]\n",
      " [130   1 114 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 126   1 101]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [116 107 112 ... 109 107 120]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1 101  99]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [107 112   7 ... 107 120   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[127   9   9 ... 101 112 129]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [ 57  49   7 ... 102 113   1]\n",
      " ...\n",
      " [116 104 110 ... 123 104 110]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  9   9   9 ... 112 129   7]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [ 49   7   1 ... 113   1 122]\n",
      " ...\n",
      " [104 110 127 ... 104 110 109]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1  79]\n",
      " ...\n",
      " [116 109 113 ...  99 101 107]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1  79   1]\n",
      " ...\n",
      " [109 113 108 ... 101 107 121]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [109  99 105 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [ 99   1 114 ...   1   1   1]\n",
      " [  1 114 113 ... 114  99 103]\n",
      " [115 109 123 ... 113 112  99]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [ 99 105 104 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1 114 104 ...   1   1   1]\n",
      " [114 113   1 ...  99 103  99]\n",
      " [109 123 107 ... 112  99 115]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   0   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [112 104 101 ... 107   1 111]\n",
      " [  1 114 113 ... 113   1 116]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [104 101 116 ...   1 111 112]\n",
      " [114 113 110 ...   1 116 117]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [108   9   0 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [104 117   1 ... 110 126 117]\n",
      " [101 104 124 ... 112 116 117]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  9   0   0 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [117   1 110 ... 126 117 127]\n",
      " [104 124 104 ... 116 117 101]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[105 104   1 ... 104   1 117]\n",
      " [101   1 114 ...  74 113 117]\n",
      " [  9   0   0 ...   7   0   1]\n",
      " ...\n",
      " [  7   0   1 ...   0   1   1]\n",
      " [102 113 112 ...   1   1   1]\n",
      " [113 108   7 ...   1 115 118]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[104   1 117 ...   1 117 113]\n",
      " [  1 114 110 ... 113 117 113]\n",
      " [  0   0   1 ...   0   1   1]\n",
      " ...\n",
      " [  0   1   1 ...   1   1   1]\n",
      " [113 112  99 ...   1   1   1]\n",
      " [108   7   0 ... 115 118 109]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[112 107 109 ...   1   1   1]\n",
      " [117   1 107 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1 130   6 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [ 82 104 122 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[107 109 112 ...   1   1   1]\n",
      " [  1 107   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [130   6   0 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [104 122 117 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [107 110  99 ...  99   7   0]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [117 115 107 ... 104   1 106]\n",
      " [  1   1   1 ...   0   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [110  99   0 ...   7   0   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [115 107   7 ...   1 106  99]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 127 104   2]\n",
      " [  9   0   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [112 104 101 ...   1 118 111]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 104   2   1]\n",
      " [  0   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [104 101 113 ... 118 111 113]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1 106  99 ...   9   1   9]\n",
      " [  1  83 113 ...   1 116 101]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 105 104 ... 111  99 110]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [106  99 111 ...   1   9   1]\n",
      " [ 83 113   1 ... 116 101 104]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [105 104   1 ...  99 110   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 112  99 116]\n",
      " [  7   0   1 ... 104 111   9]\n",
      " [ 99 101   1 ... 114 113 111]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [109 113 115 ...   1 113 112]\n",
      " [  1   1   1 ... 104 117 126]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...  99 116   1]\n",
      " [  0   1   1 ... 111   9   0]\n",
      " [101   1 101 ... 113 111 104]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [113 115 104 ... 113 112   1]\n",
      " [  1   1   1 ... 117 126 108]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  0   0   1 ... 113 104 108]\n",
      " [110  99 110 ... 104 117   7]\n",
      " ...\n",
      " [116 117 113 ... 110  99 103]\n",
      " [104 116 112 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  0   1   1 ... 104 108   7]\n",
      " [ 99 110   1 ... 117   7   1]\n",
      " ...\n",
      " [117 113 115 ...  99 103 112]\n",
      " [116 112 107 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [109  99 105 ... 103 107 123]\n",
      " [  1   1   1 ...   1 113 122]\n",
      " ...\n",
      " [  1   1   1 ...   9   0   0]\n",
      " [  1   1   1 ... 118   0   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [ 99 105 107 ... 107 123 127]\n",
      " [  1   1   1 ... 113 122 104]\n",
      " ...\n",
      " [  1   1   1 ...   0   0   1]\n",
      " [  1   1   1 ...   0   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[126   1 106 ... 127   1 123]\n",
      " [  1   1   1 ...   7   0   1]\n",
      " [101 110  99 ... 113 117 113]\n",
      " ...\n",
      " [117  21   0 ... 111  21   0]\n",
      " [121   1 119 ... 130 112  99]\n",
      " [117   1 107 ... 106 103 104]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1 106 107 ...   1 123 118]\n",
      " [  1   1   1 ...   0   1   1]\n",
      " [110  99 116 ... 117 113 101]\n",
      " ...\n",
      " [ 21   0   1 ...  21   0   1]\n",
      " [  1 119 107 ... 112  99   1]\n",
      " [  1 107   1 ... 103 104 116]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1  85]\n",
      " [112  22   0 ...   1 110 104]\n",
      " [102 110 130 ... 118 123 118]\n",
      " ...\n",
      " [  1  74 110 ...   1   1  75]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1  85 113]\n",
      " [ 22   0   1 ... 110 104 110]\n",
      " [110 130 103 ... 123 118   1]\n",
      " ...\n",
      " [ 74 110  99 ...   1  75 101]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1  80]\n",
      " [108   1 123 ... 101   1 114]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [114 115 107 ...   1   1   1]\n",
      " [  1   1   1 ...   7   0   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1  80   1]\n",
      " [  1 123 117 ...   1 114 104]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [115 107 130 ...   1   1  89]\n",
      " [  1   1   1 ...   0   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 104   1 104]\n",
      " [113 101  99 ... 110 113 112]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [127   1 101 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1 104 116]\n",
      " [101  99   9 ... 113 112 113]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 101 104 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[117   1 101 ... 104 114 107]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 104  21   0]\n",
      " ...\n",
      " [127   1 113 ... 123 107 120]\n",
      " [  1   1   1 ... 122 107 108]\n",
      " [  1 113 122 ... 113 109   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1 101 106 ... 114 107   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...  21   0   1]\n",
      " ...\n",
      " [  1 113 114 ... 107 120   1]\n",
      " [  1   1   1 ... 107 108   1]\n",
      " [113 122 104 ... 109   1 118]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[109  99 130 ...   7   1 107]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 116 101 ...   1   8   1]\n",
      " ...\n",
      " [110   1 112 ...   1   1   1]\n",
      " [  1 109  99 ...  20   0   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 99 130   1 ...   1 107   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [116 101 113 ...   8   1   3]\n",
      " ...\n",
      " [  1 112 104 ...   1   1   1]\n",
      " [109  99 109 ...   0   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [120 113 117 ... 113 108   1]\n",
      " [105 112 113 ... 111 107 110]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [130   7   0 ... 110  99   7]\n",
      " [  1   9   1 ...   1   1   9]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [113 117 104 ... 108   1  81]\n",
      " [112 113 116 ... 107 110 113]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  7   0   1 ...  99   7   0]\n",
      " [  9   1   9 ...   1   9   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[114 115 104 ...  99 110  21]\n",
      " [  1 112 104 ...   1   1  84]\n",
      " [104 110 130 ... 103 126   7]\n",
      " ...\n",
      " [104 122 112 ... 117 113 115]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[115 104 110 ... 110  21   1]\n",
      " [112 104 114 ...   1  84   1]\n",
      " [110 130 110 ... 126   7   1]\n",
      " ...\n",
      " [122 112 113 ... 113 115 102]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[111   1 110 ...   1   1   1]\n",
      " [  1   1   1 ...   1 116 112]\n",
      " [  1 102 110 ... 115 130 117]\n",
      " ...\n",
      " [112 104   1 ...  75  99 101]\n",
      " [ 99 111 130 ... 118 120 113]\n",
      " [113 122 112 ...   1  91  99]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1 110 104 ...   1   1   1]\n",
      " [  1   1   1 ... 116 112 107]\n",
      " [102 110 130 ... 130 117   9]\n",
      " ...\n",
      " [104   1 101 ...  99 101 112]\n",
      " [111 130 117 ... 120 113 101]\n",
      " [122 112 107 ...  91  99 115]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [116 112 118 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   7   0   1]\n",
      " [  1 103 112 ... 112 113 108]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [112 118 110 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   0   1   1]\n",
      " [103 112 107 ... 113 108   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 108   1 114]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [108   1 100 ... 112 126 108]\n",
      " ...\n",
      " [  1   1   1 ... 103 118 111]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 127 130   7]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1 114 127]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 100 104 ... 126 108   1]\n",
      " ...\n",
      " [  1   1   1 ... 118 111  99]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 130   7   0]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 104 101   1]\n",
      " [104   1 116 ... 111  99 110]\n",
      " [104  21   0 ... 112 104 101]\n",
      " ...\n",
      " [114 115  99 ... 113   1 114]\n",
      " [107 110  99 ... 113 104   7]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ... 101   1 113]\n",
      " [  1 116 104 ...  99 110 113]\n",
      " [ 21   0   1 ... 104 101 111]\n",
      " ...\n",
      " [115  99 101 ...   1 114 113]\n",
      " [110  99 130 ... 104   7   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[107 117  99 ... 117  21   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [110 116 130 ...   1   1   1]\n",
      " [107   1 100 ...   1   1   1]\n",
      " [103 130 111 ...  43  43  41]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[117  99 104 ...  21   1 113]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1  79 ...   1   1   1]\n",
      " ...\n",
      " [116 130   1 ...   1   1   1]\n",
      " [  1 100 126 ...   1   1   1]\n",
      " [130 111   0 ...  43  41  31]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  7   1 109 ... 101 107 110]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  7   1 109 ... 116   1 112]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 109  99 ... 107 110 107]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1 109 113 ...   1 112 107]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1  85 115 ...   1   1   1]\n",
      " ...\n",
      " [110 107 115 ... 108  22   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [ 85 115 113 ...   1   1   1]\n",
      " ...\n",
      " [107 115 107 ...  22   1   8]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 111 113 102]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [116 109 113 ... 115 113 105]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ... 113 102   0]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [109 113 101 ... 113 105  99]\n",
      " [  1   1   1 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[101 113 100 ...   1   1   1]\n",
      " [116 110 104 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...  99 103 107]\n",
      " [  1   1   1 ...   7   0   1]\n",
      " [115 112 113 ... 102   1 112]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[113 100 113 ...   1   1   1]\n",
      " [110 104 106 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ... 103 107 110]\n",
      " [  1   1   1 ...   0   1   1]\n",
      " [112 113   1 ...   1 112  99]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [110 104 101 ...  83 118   7]\n",
      " [ 99 112 104 ... 126 104   1]\n",
      " ...\n",
      " [  1   1   1 ... 114 104 123]\n",
      " [  7   0   1 ... 118 111  99]\n",
      " [  1 107   1 ...   1 102 112]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [104 101 113 ... 118   7   1]\n",
      " [112 104 112 ... 104   1 112]\n",
      " ...\n",
      " [  1   1   1 ... 104 123 107]\n",
      " [  0   1   1 ... 111  99 116]\n",
      " [107   1 111 ... 102 112 104]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 99 109   1 ... 104 115 112]\n",
      " [ 87 118 103 ...   1   1   1]\n",
      " [126 112 104 ...  99 124 107]\n",
      " ...\n",
      " [  1   1   1 ... 115 104 105]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...  99  22   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[109   1 106 ... 115 112  99]\n",
      " [118 103 127 ...   1   1   1]\n",
      " [112 104   1 ... 124 107 117]\n",
      " ...\n",
      " [  1   1   1 ... 104 105 103]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...  22   1  89]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1  75 113 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [113 108   2 ...   1 101 103]\n",
      " [  1 105 104 ... 104 102 103]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 75 113 111 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [108   2   0 ... 101 103 113]\n",
      " [105 104 115 ... 102 103  99]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [106   1 118 ...   7   1 112]\n",
      " [111 118 105 ... 116 104 111]\n",
      " ...\n",
      " [117  99 109 ...   1   1   1]\n",
      " [112 113   1 ... 116   1 105]\n",
      " [116 109 107 ...   3  72 110]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1 118 100 ...   1 112  99]\n",
      " [118 105   1 ... 104 111   1]\n",
      " ...\n",
      " [ 99 109  99 ...   1   1  85]\n",
      " [113   1 130 ...   1 105 104]\n",
      " [109 107   9 ...  72 110  99]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [112   1 101 ... 113 111   1]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  0   1   1 ...   0   1   1]\n",
      " [ 41   0   0 ... 104 117 112]\n",
      " [ 81  71  73 ...   1   1   1]], shape=(64, 100), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  1   1   1 ...   1   1   1]\n",
      " [  1 101 126 ... 111   1 109]\n",
      " [  1   1   1 ...   1   1   1]\n",
      " ...\n",
      " [  1   1   1 ...   1   1   1]\n",
      " [  0   0   1 ... 117 112 113]\n",
      " [ 71  73  71 ...   1   1   1]], shape=(64, 100), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for el1,el2 in dataset:\n",
    "    print(el1)\n",
    "    print(el2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Генерация текста по словам**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# replace '--' with a space ' '\n",
    "\tdoc = doc.replace('--', ' ')\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# make lower case\n",
    "\ttokens = [word.lower() for word in tokens]\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['александр', 'сергеевич', 'пушкин', 'евгений', 'онегин', 'роман', 'в', 'стихах', 'не', 'мысля', 'гордый', 'свет', 'забавить', 'вниманье', 'дружбы', 'возлюбя', 'хотел', 'бы', 'я', 'тебе', 'представить', 'залог', 'достойнее', 'тебя', 'достойнее', 'души', 'прекрасной', 'святой', 'исполненной', 'мечты', 'поэзии', 'живой', 'и', 'ясной', 'высоких', 'дум', 'и', 'простоты', 'но', 'так', 'и', 'быть', 'рукой', 'пристрастной', 'прими', 'собранье', 'пестрых', 'глав', 'полусмешных', 'полупечальных', 'простонародных', 'идеальных', 'небрежный', 'плод', 'моих', 'забав', 'бессонниц', 'легких', 'вдохновений', 'незрелых', 'и', 'увядших', 'лет', 'ума', 'холодных', 'наблюдений', 'и', 'сердца', 'горестных', 'замет', 'глава', 'первая', 'и', 'жить', 'торопится', 'и', 'чувствовать', 'спешит', 'кн', 'вяземский', 'i', 'мой', 'дядя', 'самых', 'честных', 'правил', 'когда', 'не', 'в', 'шутку', 'занемог', 'он', 'уважать', 'себя', 'заставил', 'и', 'лучше', 'выдумать', 'не', 'мог', 'его', 'пример', 'другим', 'наука', 'но', 'боже', 'мой', 'какая', 'скука', 'с', 'больным', 'сидеть', 'и', 'день', 'и', 'ночь', 'не', 'отходя', 'ни', 'шагу', 'прочь', 'какое', 'низкое', 'коварство', 'полуживого', 'забавлять', 'ему', 'подушки', 'поправлять', 'печально', 'подносить', 'лекарство', 'вздыхать', 'и', 'думать', 'про', 'себя', 'когда', 'же', 'черт', 'возьмет', 'тебя', 'ii', 'так', 'думал', 'молодой', 'повеса', 'летя', 'в', 'пыли', 'на', 'почтовых', 'всевышней', 'волею', 'зевеса', 'наследник', 'всех', 'своих', 'родных', 'друзья', 'людмилы', 'и', 'руслана', 'с', 'героем', 'моего', 'романа', 'без', 'предисловий', 'сей', 'же', 'час', 'позвольте', 'познакомить', 'вас', 'онегин', 'добрый', 'мой', 'приятель', 'родился', 'на', 'брегах', 'невы', 'где', 'может', 'быть', 'родились', 'вы', 'или', 'блистали', 'мой', 'читатель', 'там', 'некогда', 'гулял', 'и', 'я', 'но', 'вреден', 'север']\n",
      "Total Tokens: 23014\n",
      "Unique Tokens: 8518\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "tokens = clean_doc(text)\n",
    "print(tokens[:200])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 22963\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)    \n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сергеевич пушкин евгений онегин роман в стихах не мысля гордый свет забавить вниманье дружбы возлюбя хотел бы я тебе представить залог достойнее тебя достойнее души прекрасной святой исполненной мечты поэзии живой и ясной высоких дум и простоты но так и быть рукой пристрастной прими собранье пестрых глав полусмешных полупечальных простонародных идеальных'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = 'EOnegin.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# load\n",
    "in_filename = 'EOnegin.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 50)            425950    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8519)              860419    \n",
      "=================================================================\n",
      "Total params: 1,437,269\n",
      "Trainable params: 1,437,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - 22s 105ms/step - loss: 8.5196 - accuracy: 0.0329\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 7.8350 - accuracy: 0.0420\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 19s 106ms/step - loss: 7.6703 - accuracy: 0.0443\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 7.5345 - accuracy: 0.0448\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 7.3760 - accuracy: 0.0501\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 7.2796 - accuracy: 0.0477\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 19s 108ms/step - loss: 7.1744 - accuracy: 0.0494\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 7.0395 - accuracy: 0.0508\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 6.8933 - accuracy: 0.0511\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 19s 107ms/step - loss: 6.7875 - accuracy: 0.0504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b426615b0>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гробовой своей доски все потеряв невозвратимо и все равно надежда им лжет детским лепетом своим viii татьяна любопытным взором на воск потопленный глядит он чудно вылитым узором ей чтото чудное гласит из блюда полного водою выходят кольцы чередою и вынулось колечко ей под песенку старинных дней там мужичкито все богаты гребут\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.texts_to_sequences([seed_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for each word\n",
    "yhat = np.argmax(model.predict(encoded), axis=-1)\n",
    "#yhat = model.predict_classes(encoded, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_word = ''\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index in yhat:\n",
    "        out_word = word\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index in yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни ним и в ней ни\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод: сравнивая как лучше генерировать текст по словам или символам - лучше генерировать текст по символам, т.к. результат при одинаковом количестве эпох получается лучше.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
